{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC # SVM for classification\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.metrics import f1_score, precision_score,recall_score, confusion_matrix # Evaluation metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBClassifier # XGBoost classifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/loan_data.csv') # Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop installment column as it is highly correlated with loan amount \n",
    "df.drop('installment',axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>...</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>application_type</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.44</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>RENT</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36369.0</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.99</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20131.0</td>\n",
       "      <td>53.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>05113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>36</td>\n",
       "      <td>10.49</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>43057.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11987.0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>05113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.49</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>RENT</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5472.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24375.0</td>\n",
       "      <td>60</td>\n",
       "      <td>17.27</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24584.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  grade  sub_grade  emp_length home_ownership  \\\n",
       "0    10000.0    36     11.44      6         27          10           RENT   \n",
       "1     8000.0    36     11.99      6         26           4       MORTGAGE   \n",
       "2    15600.0    36     10.49      6         28           0           RENT   \n",
       "3     7200.0    36      6.49      7         34           6           RENT   \n",
       "4    24375.0    60     17.27      5         21           9       MORTGAGE   \n",
       "\n",
       "   annual_inc verification_status  loan_status  ... open_acc  pub_rec  \\\n",
       "0    117000.0        Not Verified            0  ...     16.0        0   \n",
       "1     65000.0        Not Verified            0  ...     17.0        0   \n",
       "2     43057.0     Source Verified            0  ...     13.0        0   \n",
       "3     54000.0        Not Verified            0  ...      6.0        0   \n",
       "4     55000.0            Verified            1  ...     13.0        0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc  initial_list_status  application_type  \\\n",
       "0    36369.0        41.8       25.0                    0        INDIVIDUAL   \n",
       "1    20131.0        53.3       27.0                    1        INDIVIDUAL   \n",
       "2    11987.0        92.2       26.0                    1        INDIVIDUAL   \n",
       "3     5472.0        21.5       13.0                    1        INDIVIDUAL   \n",
       "4    24584.0        69.8       43.0                    1        INDIVIDUAL   \n",
       "\n",
       "   mort_acc pub_rec_bankruptcies  zip_code  \n",
       "0         0                    0     22690  \n",
       "1         1                    0     05113  \n",
       "2         0                    0     05113  \n",
       "3         0                    0     00813  \n",
       "4         1                    0     11650  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Check the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) # Drop the rows with missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396030 entries, 0 to 396029\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   loan_amnt             396030 non-null  float64\n",
      " 1   term                  396030 non-null  object \n",
      " 2   int_rate              396030 non-null  float64\n",
      " 3   installment           396030 non-null  float64\n",
      " 4   grade                 396030 non-null  object \n",
      " 5   sub_grade             396030 non-null  object \n",
      " 6   emp_title             373103 non-null  object \n",
      " 7   emp_length            377729 non-null  object \n",
      " 8   home_ownership        396030 non-null  object \n",
      " 9   annual_inc            396030 non-null  float64\n",
      " 10  verification_status   396030 non-null  object \n",
      " 11  issue_d               396030 non-null  object \n",
      " 12  loan_status           396030 non-null  object \n",
      " 13  purpose               396030 non-null  object \n",
      " 14  title                 394274 non-null  object \n",
      " 15  dti                   396030 non-null  float64\n",
      " 16  earliest_cr_line      396030 non-null  object \n",
      " 17  open_acc              396030 non-null  float64\n",
      " 18  pub_rec               396030 non-null  float64\n",
      " 19  revol_bal             396030 non-null  float64\n",
      " 20  revol_util            395754 non-null  float64\n",
      " 21  total_acc             396030 non-null  float64\n",
      " 22  initial_list_status   396030 non-null  object \n",
      " 23  application_type      396030 non-null  object \n",
      " 24  mort_acc              358235 non-null  float64\n",
      " 25  pub_rec_bankruptcies  395495 non-null  float64\n",
      " 26  address               396030 non-null  object \n",
      "dtypes: float64(12), object(15)\n",
      "memory usage: 81.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Check the data types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_ownership\n",
      "MORTGAGE    170831\n",
      "RENT        133932\n",
      "OWN          31045\n",
      "OTHER           59\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/jm00596j00189w93nrcppm1r0000gn/T/ipykernel_47514/2547704004.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
      "/var/folders/v_/jm00596j00189w93nrcppm1r0000gn/T/ipykernel_47514/2547704004.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n"
     ]
    }
   ],
   "source": [
    "# Mapping of target variable -\n",
    "\n",
    "\n",
    "df.loc[(df.home_ownership == 'ANY') | (df.home_ownership == 'NONE'), 'home_ownership'] = 'OTHER'\n",
    "print(df.home_ownership.value_counts())\n",
    "\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "\n",
    "def pub_rec(number):\n",
    "    if number == 0.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def mort_acc(number):\n",
    "    if number == 0.0:\n",
    "        return 0\n",
    "    elif number >= 1.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return number\n",
    "\n",
    "def pub_rec_bankruptcies(number):\n",
    "    if number == 0.0:\n",
    "        return 0\n",
    "    elif number >= 1.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return number\n",
    "\n",
    "\n",
    "df['pub_rec'] = df.pub_rec.apply(pub_rec)\n",
    "df['mort_acc'] = df.mort_acc.apply(mort_acc)\n",
    "df['pub_rec_bankruptcies'] = df.pub_rec_bankruptcies.apply(pub_rec_bankruptcies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "Fully Paid     269555\n",
      "Charged Off     66312\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 335867 entries, 0 to 396028\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   loan_amnt             335867 non-null  float64       \n",
      " 1   term                  335867 non-null  object        \n",
      " 2   int_rate              335867 non-null  float64       \n",
      " 3   grade                 335867 non-null  object        \n",
      " 4   sub_grade             335867 non-null  object        \n",
      " 5   emp_title             335867 non-null  object        \n",
      " 6   emp_length            335867 non-null  object        \n",
      " 7   home_ownership        335867 non-null  object        \n",
      " 8   annual_inc            335867 non-null  float64       \n",
      " 9   verification_status   335867 non-null  object        \n",
      " 10  issue_d               335867 non-null  datetime64[ns]\n",
      " 11  loan_status           335867 non-null  object        \n",
      " 12  purpose               335867 non-null  object        \n",
      " 13  title                 335867 non-null  object        \n",
      " 14  dti                   335867 non-null  float64       \n",
      " 15  earliest_cr_line      335867 non-null  datetime64[ns]\n",
      " 16  open_acc              335867 non-null  float64       \n",
      " 17  pub_rec               335867 non-null  int64         \n",
      " 18  revol_bal             335867 non-null  float64       \n",
      " 19  revol_util            335867 non-null  float64       \n",
      " 20  total_acc             335867 non-null  float64       \n",
      " 21  initial_list_status   335867 non-null  object        \n",
      " 22  application_type      335867 non-null  object        \n",
      " 23  mort_acc              335867 non-null  int64         \n",
      " 24  pub_rec_bankruptcies  335867 non-null  int64         \n",
      " 25  address               335867 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(8), int64(3), object(13)\n",
      "memory usage: 69.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.loan_status.value_counts())\n",
    "\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_values = {' 36 months': 36, ' 60 months': 60}\n",
    "df['term'] = df.term.map(term_values)\n",
    "\n",
    "list_status = {'w': 0, 'f': 1}\n",
    "df['initial_list_status'] = df.initial_list_status.map(list_status)\n",
    "\n",
    "# Let's fetch ZIP from address and then drop the remaining details -\n",
    "df['zip_code'] = df.address.apply(lambda x: x[-5:])\n",
    "\n",
    "# Dropping some variables which IMO we can let go for now -\n",
    "df.drop(columns=['issue_d', 'emp_title', 'title',\n",
    "                   'address', 'earliest_cr_line'],\n",
    "                   axis=1, inplace=True) \n",
    "\n",
    "emp_len_to_int = {'10+ years': 10, '4 years': 4, '< 1 year': 0, '6 years': 6, '9 years': 9, '2 years': 2, \n",
    "                  '3 years': 3, '8 years': 8, '7 years': 7, '5 years': 5, '1 year': 1, 'nan': np.nan} \n",
    "\n",
    "\n",
    "grade_to_int = {'A':7, 'B':6, 'C':5, 'D':4, 'E':3, 'F':2, 'G':1}\n",
    "\n",
    "sub_grade_to_int = {'A1':35, 'A2':34, 'A3':33, 'A4':32, 'A5':31, \n",
    "                    'B1':30, 'B2':29, 'B3':28, 'B4':27, 'B5':26, \n",
    "                    'C1':25, 'C2':24, 'C3':23, 'C4':22, 'C5':21, \n",
    "                    'D1':20, 'D2':19, 'D3':18, 'D4':17, 'D5':16, \n",
    "                    'E1':15, 'E2':14, 'E3':13, 'E4':12, 'E5':11, \n",
    "                    'F1':10, 'F2':9, 'F3':8, 'F4':7, 'F5':6, \n",
    "                    'G1':5, 'G2':4, 'G3':3, 'G4':2, 'G5':1}\n",
    "\n",
    "df['emp_length'] = df['emp_length'].apply(lambda x: emp_len_to_int[str(x).split('-')[0]])  \n",
    "\n",
    "df['grade'] = df['grade'].apply(lambda x: grade_to_int[str(x).split('-')[0]])\n",
    "df['sub_grade'] = df['sub_grade'].apply(lambda x: sub_grade_to_int[str(x).split('-')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_status_values = {'Fully Paid': 0, 'Charged Off': 1} \n",
    "# df['loan_status'] = df.loan_status.map(loan_status_values)  \n",
    "# df['loan_status'] = df['loan_status'].map({'Fully Paid': 0, 'Charged Off': 1})\n",
    "df['loan_status'] = df['loan_status'].apply(lambda x: 0 if x == 'Fully Paid' else 1)\n",
    "df['loan_status'] = df['loan_status'].astype('int64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335867, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing outliers: (319771, 22)\n"
     ]
    }
   ],
   "source": [
    "numerical_data = df.select_dtypes(include='number')\n",
    "num_cols = numerical_data.columns\n",
    "len(num_cols)\n",
    "for col in num_cols:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "\n",
    "    upper_limit = mean+3*std\n",
    "    lower_limit = mean-3*std\n",
    "\n",
    "    df = df[(df[col]<upper_limit) & (df[col]>lower_limit)]\n",
    "\n",
    "print(f\"After removing outliers: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = df.select_dtypes(include=\"object\").columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319771, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_length',\n",
       "       'annual_inc', 'loan_status', 'dti', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'initial_list_status', 'mort_acc',\n",
       "       'pub_rec_bankruptcies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 319771 entries, 0 to 396028\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   loan_amnt             319771 non-null  float64\n",
      " 1   term                  319771 non-null  int64  \n",
      " 2   int_rate              319771 non-null  float64\n",
      " 3   grade                 319771 non-null  int64  \n",
      " 4   sub_grade             319771 non-null  int64  \n",
      " 5   emp_length            319771 non-null  int64  \n",
      " 6   home_ownership        319771 non-null  object \n",
      " 7   annual_inc            319771 non-null  float64\n",
      " 8   verification_status   319771 non-null  object \n",
      " 9   loan_status           319771 non-null  int64  \n",
      " 10  purpose               319771 non-null  object \n",
      " 11  dti                   319771 non-null  float64\n",
      " 12  open_acc              319771 non-null  float64\n",
      " 13  pub_rec               319771 non-null  int64  \n",
      " 14  revol_bal             319771 non-null  float64\n",
      " 15  revol_util            319771 non-null  float64\n",
      " 16  total_acc             319771 non-null  float64\n",
      " 17  initial_list_status   319771 non-null  int64  \n",
      " 18  application_type      319771 non-null  object \n",
      " 19  mort_acc              319771 non-null  int64  \n",
      " 20  pub_rec_bankruptcies  319771 non-null  int64  \n",
      " 21  zip_code              319771 non-null  object \n",
      "dtypes: float64(8), int64(9), object(5)\n",
      "memory usage: 56.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df, col):\n",
    "    '''\n",
    "    This function removes the outliers from the column passed in the argument\n",
    "    '''\n",
    "    q1 = df[col].quantile(0.25) # 25th quantile\n",
    "    q3 = df[col].quantile(0.75) # 75th quantile\n",
    "    iqr = q3-q1 # Interquartile range\n",
    "    fence_low  = q1-1.5*iqr # Inner fence\n",
    "    fence_high = q3+1.5*iqr # Outer fence\n",
    "    df_out = df.loc[(df[col] > fence_low) & (df[col] < fence_high)] # Data within inner and outer fence\n",
    "    return df_out # Return the dataframe with outliers removed \n",
    "\n",
    "# remove outliers from all the columns using the above function and for loop\n",
    "for col in num_features:\n",
    "    df = remove_outlier(df, col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 319771 entries, 0 to 396028\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   loan_amnt             319771 non-null  float64\n",
      " 1   term                  319771 non-null  int64  \n",
      " 2   int_rate              319771 non-null  float64\n",
      " 3   grade                 319771 non-null  int64  \n",
      " 4   sub_grade             319771 non-null  int64  \n",
      " 5   emp_length            319771 non-null  int64  \n",
      " 6   home_ownership        319771 non-null  object \n",
      " 7   annual_inc            319771 non-null  float64\n",
      " 8   verification_status   319771 non-null  object \n",
      " 9   loan_status           319771 non-null  int64  \n",
      " 10  purpose               319771 non-null  object \n",
      " 11  dti                   319771 non-null  float64\n",
      " 12  open_acc              319771 non-null  float64\n",
      " 13  pub_rec               319771 non-null  int64  \n",
      " 14  revol_bal             319771 non-null  float64\n",
      " 15  revol_util            319771 non-null  float64\n",
      " 16  total_acc             319771 non-null  float64\n",
      " 17  initial_list_status   319771 non-null  int64  \n",
      " 18  application_type      319771 non-null  object \n",
      " 19  mort_acc              319771 non-null  int64  \n",
      " 20  pub_rec_bankruptcies  319771 non-null  int64  \n",
      " 21  zip_code              319771 non-null  object \n",
      "dtypes: float64(8), int64(9), object(5)\n",
      "memory usage: 56.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Check the data types of the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_ownership\n",
      "MORTGAGE    160550\n",
      "RENT        129950\n",
      "OWN          29213\n",
      "OTHER           58\n",
      "Name: count, dtype: int64\n",
      "**************************************************\n",
      "verification_status\n",
      "Source Verified    109788\n",
      "Not Verified       105112\n",
      "Verified           104871\n",
      "Name: count, dtype: int64\n",
      "**************************************************\n",
      "purpose\n",
      "debt_consolidation    195023\n",
      "credit_card            69386\n",
      "home_improvement       18248\n",
      "other                  15309\n",
      "major_purchase          6065\n",
      "small_business          3087\n",
      "medical                 3071\n",
      "car                     2976\n",
      "moving                  2063\n",
      "vacation                1890\n",
      "house                   1537\n",
      "wedding                  902\n",
      "renewable_energy         214\n",
      "Name: count, dtype: int64\n",
      "**************************************************\n",
      "application_type\n",
      "INDIVIDUAL    319427\n",
      "JOINT            265\n",
      "DIRECT_PAY        79\n",
      "Name: count, dtype: int64\n",
      "**************************************************\n",
      "zip_code\n",
      "70466    45993\n",
      "30723    45720\n",
      "22690    45559\n",
      "48052    45217\n",
      "00813    36986\n",
      "29597    36730\n",
      "05113    36647\n",
      "93700     9041\n",
      "11650     8990\n",
      "86630     8888\n",
      "Name: count, dtype: int64\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "print(df.home_ownership.value_counts())\n",
    "print(\"*\"*50)\n",
    "print(df.verification_status.value_counts())\n",
    "print(\"*\"*50)\n",
    "print(df.purpose.value_counts()) \n",
    "print(\"*\"*50)\n",
    "print(df.application_type.value_counts())\n",
    "print(\"*\"*50)\n",
    "print(df.zip_code.value_counts()) \n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('loan_status', axis=1)\n",
    "y = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((255816, 21), (63955, 21))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted) :\n",
    "    '''Write a code to evaluate the model using the following metrics: F1 score, Accuracy, Precision, Recall, and Confusion Matrix.'''\n",
    "    from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "    print('F1 score: ', f1_score(true, predicted))\n",
    "    print('Accuracy: ', accuracy_score(true, predicted))\n",
    "    print('Precision: ', precision_score(true, predicted))\n",
    "    print('Recall: ', recall_score(true, predicted))\n",
    "    print('Confusion Matrix: ', confusion_matrix(true, predicted))\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "         (\"StandardScaler\", numeric_transformer, num_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train) # Fit and transform the training data\n",
    "X_test = preprocessor.transform(X_test) # Transform the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((268693, 21), (67174, 21))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted) :\n",
    "    '''Write a code to evaluate the model using the following metrics: F1 score, Accuracy, Precision, Recall, and Confusion Matrix.'''\n",
    "    from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "    f1_score_1 =  f1_score(true, predicted)\n",
    "    accuracy_score_1 = accuracy_score(true, predicted)\n",
    "    precision_score_1 = precision_score(true, predicted)\n",
    "    recall_score_1 = recall_score(true, predicted)\n",
    "    # confusion_matrix_1 = confusion_matrix(true, predicted)\n",
    "    return f1_score_1, accuracy_score_1, precision_score_1, recall_score_1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Regressor\": RandomForestClassifier(),\n",
    "    \"XGBRegressor\": XGBClassifier(), \n",
    "    \"AdaBoost Regressor\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudhirmalik/Documents/Scaler class notes/MLOPS/Loan_Tap_MLOPS/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- F_1 Score: 0.6225\n",
      "- Accuracy Score: 0.8115\n",
      "- Precision Score: 0.5126\n",
      "- Recall Score: 0.7925\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F_1 Score: 0.6245\n",
      "- Accuracy Score: 0.8122\n",
      "- Precision Score: 0.5129\n",
      "- Recall Score: 0.7983\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree Classifier\n",
      "Model performance for Training set\n",
      "- F_1 Score: 1.0000\n",
      "- Accuracy Score: 1.0000\n",
      "- Precision Score: 1.0000\n",
      "- Recall Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F_1 Score: 0.5834\n",
      "- Accuracy Score: 0.8357\n",
      "- Precision Score: 0.5787\n",
      "- Recall Score: 0.5883\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "Model performance for Training set\n",
      "- F_1 Score: 1.0000\n",
      "- Accuracy Score: 1.0000\n",
      "- Precision Score: 1.0000\n",
      "- Recall Score: 0.9999\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F_1 Score: 0.6242\n",
      "- Accuracy Score: 0.8901\n",
      "- Precision Score: 0.9433\n",
      "- Recall Score: 0.4665\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- F_1 Score: 0.6538\n",
      "- Accuracy Score: 0.8258\n",
      "- Precision Score: 0.5356\n",
      "- Recall Score: 0.8391\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F_1 Score: 0.6250\n",
      "- Accuracy Score: 0.8111\n",
      "- Precision Score: 0.5110\n",
      "- Recall Score: 0.8045\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- F_1 Score: 0.6191\n",
      "- Accuracy Score: 0.8890\n",
      "- Precision Score: 0.9464\n",
      "- Recall Score: 0.4600\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F_1 Score: 0.6266\n",
      "- Accuracy Score: 0.8907\n",
      "- Precision Score: 0.9442\n",
      "- Recall Score: 0.4689\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced'),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(class_weight='balanced'),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"XGBRegressor\": XGBClassifier(scale_pos_weight=sum(y_train==0)/sum(y_train==1)), \n",
    "    \"AdaBoost Regressor\": AdaBoostClassifier()\n",
    "}\n",
    "model_list = []\n",
    "f1_score_list = []\n",
    "accuracy_score_list =[]\n",
    "precision_score_list = []\n",
    "recall_score_list = [] \n",
    " \n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model \n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate Train and Test dataset\n",
    "    f1_score_train , accuracy_score_train, precision_score_train, recall_score_train  = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    f1_score_test , accuracy_score_test, precision_score_test, recall_score_test = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- F_1 Score: {:.4f}\".format(f1_score_train))\n",
    "    print(\"- Accuracy Score: {:.4f}\".format(accuracy_score_train))\n",
    "    print(\"- Precision Score: {:.4f}\".format(precision_score_train))\n",
    "    print(\"- Recall Score: {:.4f}\".format(recall_score_train))\n",
    "    # print(\"- Confusion Matrix: {:.4f}\".format(confusion_matrix_train))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- F_1 Score: {:.4f}\".format(f1_score_test))\n",
    "    print(\"- Accuracy Score: {:.4f}\".format(accuracy_score_test))\n",
    "    print(\"- Precision Score: {:.4f}\".format(precision_score_test))\n",
    "    print(\"- Recall Score: {:.4f}\".format(recall_score_test))\n",
    "    # print(\"- Confusion Matrix: {:.4f}\".format(confusion_matrix_test))\n",
    "    f1_score_list.append(f1_score_test)\n",
    "    accuracy_score_list.append(accuracy_score_test)\n",
    "    precision_score_list.append(precision_score_test)\n",
    "    recall_score_list.append(recall_score_list)\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
